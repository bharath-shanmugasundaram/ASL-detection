{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1745a0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as t\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision._utils as util\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2 as cv\n",
    "import os\n",
    "import sklearn.model_selection as sc\n",
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "12121b9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[255,   1,   1],\n",
       "        [250,   0,   0],\n",
       "        [247,   0,   2],\n",
       "        ...,\n",
       "        [241,   0,   5],\n",
       "        [245,   1,   1],\n",
       "        [249,   5,   0]],\n",
       "\n",
       "       [[252,   1,   2],\n",
       "        [237,   3,   5],\n",
       "        [208,   7,  11],\n",
       "        ...,\n",
       "        [196,   7,  16],\n",
       "        [209,   3,   2],\n",
       "        [219,   5,   0]],\n",
       "\n",
       "       [[241,   0,   1],\n",
       "        [207,   8,  12],\n",
       "        [186,  76,  82],\n",
       "        ...,\n",
       "        [189, 112, 120],\n",
       "        [243, 112, 115],\n",
       "        [170,  12,  12]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[240,   0,   4],\n",
       "        [193,   5,  10],\n",
       "        [144,  68,  69],\n",
       "        ...,\n",
       "        [144, 129, 133],\n",
       "        [219, 128, 131],\n",
       "        [140,  14,  13]],\n",
       "\n",
       "       [[248,   0,   1],\n",
       "        [222,  11,  14],\n",
       "        [190,  54,  56],\n",
       "        ...,\n",
       "        [219, 129, 129],\n",
       "        [252, 119, 116],\n",
       "        [169,  16,   9]],\n",
       "\n",
       "       [[252,   1,   2],\n",
       "        [224,   2,   2],\n",
       "        [173,   8,  11],\n",
       "        ...,\n",
       "        [138,  12,  11],\n",
       "        [173,  17,  12],\n",
       "        [179,  10,   2]]], shape=(200, 200, 3), dtype=uint8)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = cv.imread(\"../Dataset/asl_alphabet_test/asl_alphabet_test/A_test.jpg\")\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8c62252",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/bhara-zstch1566/CNN/Project/ResNet/Dataset/asl_alphabet_train/asl_alphabet_train'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      2\u001b[39m y_train = []\n\u001b[32m      4\u001b[39m folder_path = \u001b[33m\"\u001b[39m\u001b[33m/Users/bhara-zstch1566/CNN/Project/ResNet/Dataset/asl_alphabet_train/asl_alphabet_train\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m foldername \u001b[38;5;129;01min\u001b[39;00m \u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfolder_path\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m      8\u001b[39m     inside = (folder_path+\u001b[33m\"\u001b[39m\u001b[33m/\u001b[39m\u001b[33m\"\u001b[39m+foldername)\n\u001b[32m      9\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m filename \u001b[38;5;129;01min\u001b[39;00m os.listdir(inside):\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: '/Users/bhara-zstch1566/CNN/Project/ResNet/Dataset/asl_alphabet_train/asl_alphabet_train'"
     ]
    }
   ],
   "source": [
    "x_train = []\n",
    "y_train = []\n",
    "\n",
    "folder_path = \"/Users/bhara-zstch1566/CNN/Project/ResNet/Dataset/asl_alphabet_train/asl_alphabet_train\"\n",
    "\n",
    "for foldername in os.listdir(folder_path):\n",
    "    \n",
    "    inside = (folder_path+\"/\"+foldername)\n",
    "    for filename in os.listdir(inside):\n",
    "        img = cv.imread(inside+'/'+filename)\n",
    "        x_train.append(img)\n",
    "        y_train.append(foldername)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "170d5b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "label = np.unique(y_train).sort()\n",
    "\n",
    "lab = sorted(list(set(y_train)),key=lambda x:x.upper())\n",
    "mapping = {}\n",
    "for ind,i in enumerate(lab):\n",
    "    mapping[i]=ind+1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a535f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(y_train)):\n",
    "    y_train[i]=mapping[y_train[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7544fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a1fb17",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = {\"image\":[],\"label\":[]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59fb3771",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(y_train)):\n",
    "    dataset['image'].append(x_train[i])\n",
    "    dataset[\"label\"].append(y_train[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b91e061",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['image']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f324535a",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),                   \n",
    "    transforms.Grayscale(num_output_channels=1),  # convert to grayscale\n",
    "    transforms.Resize((64, 64)),                  # resize\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5])   # normalize grayscale\n",
    "])\n",
    "\n",
    "\n",
    "def preprocess(example):\n",
    "    example[\"image\"] = [transform(img) for img in example[\"image\"]]\n",
    "    return example\n",
    "dataset = preprocess(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e095da",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dataset['image'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e2ba74",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['image']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf01bbc",
   "metadata": {},
   "source": [
    "## Train Test Dev split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca6277ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_dev,y_train,y_dev = sc.train_test_split(dataset['image'],dataset['label'],test_size=0.30,random_state=42,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32110720",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train,y_dev = t.tensor(y_train),t.tensor(y_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b24d207f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_dev = t.stack(x_train),t.stack(x_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee9f5357",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d81ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_dev.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c9c5736",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_dev.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c879720",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73272cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test,x_dev,y_test,y_dev = sc.train_test_split(x_dev,y_dev,test_size=0.50,random_state=42,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ad7824",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_train.shape,x_dev.shape,x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9070c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_dataset = TensorDataset(x_train, y_train)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "dev_dataset = TensorDataset(x_dev, y_dev)\n",
    "dev_loader = DataLoader(dev_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "test_dataset = TensorDataset(x_test,y_test)\n",
    "test_loader = DataLoader(test_dataset,batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dee09d7",
   "metadata": {},
   "source": [
    "## Model   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da150c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv(input_channels,output_channels):\n",
    "    return  nn.Sequential(\n",
    "        nn.Conv2d(input_channels,output_channels,3,1,1),\n",
    "        nn.ReLU(),\n",
    "        nn.Conv2d(output_channels,output_channels,3,1,1),\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool2d(2,2)\n",
    "    )\n",
    "\n",
    "class VGG16(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VGG16,self).__init__()\n",
    "        self.layer = nn.Sequential(\n",
    "            conv(1,64),\n",
    "            conv(64,128),\n",
    "            conv(128,256),\n",
    "            conv(256,512),\n",
    "            conv(512,512)\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(512*2*2, 4096),  \n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(4096, 30)\n",
    "        )\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.layer(x)\n",
    "        x = t.flatten(x, 1) \n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d6a685e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VGG16()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(),lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d06e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"mps\" if t.mps.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d6a4938",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c35755",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 5\n",
    "device = \"mps\" if t.mps.is_available() else \"cpu\"\n",
    "model = model.to(device)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    cnt = 0\n",
    "    for x, y in train_loader:         \n",
    "        x, y = x.to(device), y.to(device)\n",
    "        \n",
    "        y_pred = model(x)\n",
    "        loss = criterion(y_pred, y)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with t.no_grad():\n",
    "        for x,y in dev_loader:\n",
    "\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            \n",
    "            outputs = model(x)\n",
    "            _, predicted = t.max(outputs.data, 1)\n",
    "            total += y.size(0)\n",
    "            correct += (predicted == y).sum().item()\n",
    "    \n",
    "    print(f\"Epoch [{epoch+1}/{5}], Loss: {running_loss / len(train_loader):.4f}, Dev Accuracy: {100*correct/total:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9faf3dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "with t.no_grad():\n",
    "    for x,y in test_loader:\n",
    "        \n",
    "        x, y = x.to(device), y.to(device)\n",
    "        \n",
    "        outputs = model(x)\n",
    "        _, predicted = t.max(outputs.data, 1)\n",
    "        total += y.size(0)\n",
    "        correct += (predicted == y).sum().item()\n",
    "\n",
    "print(f\"Test Accuracy: {100*correct/total:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "074889d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img = cv.imread(\"/Users/bhara-zstch1566/CNN/Project/ResNet/Dataset/asl_alphabet_test/asl_alphabet_test/A_test.jpg\")\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),                   \n",
    "    transforms.Grayscale(num_output_channels=1),  \n",
    "    transforms.Resize((64, 64)),                 \n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5])  \n",
    "])\n",
    "\n",
    "\n",
    "test_img = transform(test_img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d0f34d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img\n",
    "test_img = test_img.unsqueeze(0)  # shape: [1, 1, 64, 64]\n",
    "device = \"mps\" if t.mps.is_available() else \"cpu\"\n",
    "test_img = test_img.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4edd367",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with t.no_grad():\n",
    "    out = model(test_img)\n",
    "    _, predicted = t.max(out.data, 1)\n",
    "\n",
    "print(f\"The predicted word in the picture is : '{lab[(predicted.item())-1]}'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bafc0420",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = \"/Users/bhara-zstch1566/CNN/Project/ResNet/Dataset/asl_alphabet_test/asl_alphabet_test\"\n",
    "crt = 0\n",
    "tot = 0\n",
    "for foldername in os.listdir(folder_path):\n",
    "    \n",
    "        img = cv.imread((folder_path+\"/\"+foldername))\n",
    "        transform = transforms.Compose([\n",
    "            transforms.ToPILImage(),                   \n",
    "            transforms.Grayscale(num_output_channels=1),  \n",
    "            transforms.Resize((64, 64)),                 \n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.5], std=[0.5])  \n",
    "        ])\n",
    "        test_img = transform(img)\n",
    "        test_img = test_img.unsqueeze(0)  # shape: [1, 1, 64, 64]\n",
    "        device = \"mps\" if t.mps.is_available() else \"cpu\"\n",
    "        test_img = test_img.to(device)\n",
    "\n",
    "        print()\n",
    "        pred = foldername.split('_')\n",
    "        with t.no_grad():\n",
    "            out = model(test_img)\n",
    "            _, predicted = t.max(out.data, 1)\n",
    "        tot+=1\n",
    "        crt += 1 if lab[(predicted.item())-1]==pred[0] else 0\n",
    "        print(f\"The predicted word in the picture is : '{lab[(predicted.item())-1]}' and actual word is : '{pred[0]}' output {lab[(predicted.item())-1]==pred[0]}\")\n",
    "\n",
    "print(f\"\\naccuracy : {crt/tot *100}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc57729f",
   "metadata": {},
   "outputs": [],
   "source": [
    "t.save(model.state_dict(), \"model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df14958",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cef077f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
